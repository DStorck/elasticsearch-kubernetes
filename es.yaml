apiVersion: v1
kind: ServiceAccount
metadata:
  name: elasticsearch
---
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  labels:
    app: elasticsearch
spec:
  ports:
  - port: 9200
    name: http
  clusterIP: None
  selector:
    name: elasticsearch-data
---
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch-cluster
  labels:
    app: elasticsearch-cluster
spec:
  ports:
  - port: 9300
    name: cluster-comms
  clusterIP: None
  selector:
    app: elasticsearch
---
apiVersion: apps/v1alpha1
kind: StatefulSet
metadata:
  name: elasticsearch-master
spec:
  serviceName: "elasticsearch-master"
  replicas: 3
  template:
    metadata:
      labels:
        app: elasticsearch
        name: elasticsearch-master
      annotations:
        pod.alpha.kubernetes.io/initialized: "true"
        pod.alpha.kubernetes.io/init-containers: '[
            {
                "name": "max-map-count-set",
                "image": "quay.io/samsung_cnct/set_max_map_count:1.1",
                "volumeMounts": [
                    {
                        "name": "hostproc",
                        "mountPath": "/hostproc"
                    }
                ]
            }]'
    spec:
      serviceAccount: elasticsearch
      serviceAccountName: elasticsearch
      containers:
      - name: elasticsearch
        image: quay.io/samsung_cnct/elasticsearch:0.1
        ports:
        - name: cluster-comms
          containerPort: 9300
        #  resource notes:  master is light weight so half a CPU.  Less then 4GB causes the container to OOM
        resources:
          limits:
            cpu: 500m
            memory: 4Gi
          requests:
            cpu: 500m
            memory: 4Gi
        env:
        - name: CLUSTER_NAME
          value: "elasticsearch-cluster"
        - name: NODE_DATA
          value: "false"
        - name: NODE_MASTER
          value: "true"
        - name: SERVICE
          value: "elasticsearch-cluster"
        #  the min/max *must* be the same due to elasticsearch 5.0 bootstrap checks
        - name: ES_JAVA_OPTS
          value: "-Xms3g -Xmx3g -Djava.net.preferIPv4Stack=true"
        - name: KUBERNETES_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        imagePullPolicy: Always
        volumeMounts:
        - name: esdata
          mountPath: /usr/share/elasticsearch/data
      volumes:
      - name: hostproc
        hostPath:
          path: /proc
  volumeClaimTemplates:
  - metadata:
      name: esdata
      annotations:
        volume.alpha.kubernetes.io/storage-class: anything
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          #  set to small so when exploring with this the user doesn't accidentally create very large disks
          storage: 20Gi
---
apiVersion: apps/v1alpha1
kind: PetSet
metadata:
  name: elasticsearch-data
spec:
  serviceName: "elasticsearch-data"
  replicas: 3
  template:
    metadata:
      labels:
        app: elasticsearch
        name: elasticsearch-data
      annotations:
        pod.alpha.kubernetes.io/initialized: "true"
        pod.alpha.kubernetes.io/init-containers: '[
            {
                "name": "max-map-count-set",
                "image": "quay.io/samsung_cnct/set_max_map_count:1.1",
                "volumeMounts": [
                    {
                        "name": "hostproc",
                        "mountPath": "/hostproc"
                    }
                ]
            }]'
    spec:
      serviceAccount: elasticsearch
      serviceAccountName: elasticsearch
      containers:
      - name: elasticsearch
        image: quay.io/samsung_cnct/elasticsearch:0.1
        ports:
        - name: cluster-comms
          containerPort: 9300
        - name: http
          containerPort: 9200
        #  resource notes:  datanodes are pretty heavy.  These should be modified up for a real production setting
        #  recommendation is two cores and 20GB of memory for the containers
        resources:
          limits:
            cpu: 500m
            memory: 4Gi
          requests:
            cpu: 500m
            memory: 4Gi
        env:
        - name: CLUSTER_NAME
          value: "elasticsearch-cluster"
        - name: NODE_DATA
          value: "true"
        - name: NODE_MASTER
          value: "false"
        - name: SERVICE
          value: "elasticsearch-cluster"
        #  the min/max *must* be the same due to elasticsearch 5.0 bootstrap checks.  For a production settings
        #  this should be 16GB.  Don't go over 32GB as the JVM starts to have issues.
        - name: ES_JAVA_OPTS
          value: "-Xms3g -Xmx3g -Djava.net.preferIPv4Stack=true"
        - name: KUBERNETES_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        imagePullPolicy: Always
        volumeMounts:
        - name: esdata
          mountPath: /usr/share/elasticsearch/data
      volumes:
      - name: hostproc
        hostPath:
          path: /proc
  volumeClaimTemplates:
  - metadata:
      name: esdata
      annotations:
        volume.alpha.kubernetes.io/storage-class: anything
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          #  set to small so when exploring with this the user doesn't accidentally create very large disks
          storage: 20Gi
